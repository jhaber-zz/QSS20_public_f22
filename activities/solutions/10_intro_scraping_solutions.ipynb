{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to web-scraping: Solutions\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "* [URL collection with automated Google search](#URLs)\n",
    "    * [Scraping school URLs](#school_URLs)\n",
    "    * [Scraping URLs using an exclusion list](#exclusionlist)\n",
    "* [Making `Requests`](#request)\n",
    "* [Parsing HTML](#parsing)\n",
    "    * [Pretty parsing with `BeautifulSoup`](#BS)\n",
    "    * [Getting human-readable text](#readable)\n",
    "\n",
    "**__________________________________**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL collection with automated Google search<a id='URLs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping school URLs<a id='school_URLs'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ccpcs.org/\n",
      "https://www.ccpcs.org/about/our-staff\n",
      "https://www.ccpcs.org/about/our-staff/join-our-team\n",
      "https://www.ccpcs.org/current-families/calendar\n",
      "https://www.ccpcs.org/about/our-staff/high-school\n",
      "https://www.facebook.com/CapitalCityPCS/\n",
      "https://www.myschooldc.org/schools/profile/143\n",
      "https://www.niche.com/k12/capital-city-public-charter-school-washington-dc/\n",
      "https://nces.ed.gov/ccd/districtsearch/district_detail.asp?Search=1&State=11&details=5&ID2=1100035\n",
      "https://www.usnews.com/education/k12/district-of-columbia/capital-city-pcs-lower-school-226373\n"
     ]
    }
   ],
   "source": [
    "# Import automated Google search package\n",
    "from googlesearch import search\n",
    "\n",
    "# Define metadata for a single entity: a DC charter school\n",
    "school_name = 'Capital City Public Charter School'\n",
    "school_address = '100 Peabody Street NW, Washington, DC 20011'\n",
    "\n",
    "# Search for first 10 Google results using joined metadata, show each one\n",
    "for url in search(school_name + ' ' + school_address, \\\n",
    "                  stop=10, pause=5.0):\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the first 10 results from Google for Dr. David C. Walker Intermediate School located at 6500 Ih 35 N Ste C, San Antonio, TX 78218. What do you notice about the results? How do they compare to the previous set of results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.niche.com/k12/dr-david-c-walker-intermediate-school-san-antonio-tx/\n",
      "https://www.mapquest.com/us/texas/dr-david-c-walker-intermediate-school-438581037\n",
      "https://www.usnews.com/education/k12/texas/dr-david-c-walker-elementary-206298\n",
      "https://www.greatschools.org/texas/san-antonio/12035-Dr-David-C-Walker-Intermediate-School/\n",
      "https://yellow.place/en/dr-david-c-walker-int-san-antonio-tx-usa\n",
      "https://elementaryschools.org/directory/tx/cities/san-antonio/dr-david-c-walker-elementary/480006211404/\n",
      "https://www.publicschoolreview.com/dr-david-c-walker-elementary-school-profile\n",
      "https://www.schoolsnearme.net/en/public/dr-david-c-walker-elementary/79869\n",
      "https://closelocation.com/find-school/dr-david-c-walker-elementary-school-school-in-basse-basse-16-11508-1216-80\n",
      "https://www.homefacts.com/schools/Texas/Bexar-County/San-Antonio/Dr-David-C-Walker-El.html\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "# Define metadata\n",
    "school_name = 'Dr. David C. Walker Intermediate School'\n",
    "school_address = '6500 Ih 35 N Ste C, San Antonio, TX 78218'\n",
    "\n",
    "# Automated search\n",
    "for url in search(school_name + ' ' + school_address, \\\n",
    "                  stop=10, pause=5.0):\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are much less clear and organized: Each one points to a different site, and all of them are third parties. Why would this be the case? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping URLs using an exclusion list<a id='exclusionlist'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully collected Google search results.\n",
      "Bad site detected: https://www.niche.com/k12/dr-david-c-walker-intermediate-school-san-antonio-tx/\n",
      "Success! URL obtained by Google search with 1 bad URLs avoided.\n",
      "Quality URL: https://www.mapquest.com/us/texas/dr-david-c-walker-intermediate-school-438581037\n"
     ]
    }
   ],
   "source": [
    "# Initial version of code\n",
    "\n",
    "# Define excluded domains to filter out: third-party domains/false positives that we DON'T want to scrape \n",
    "exclusions = ['facebook.com', 'greatschools.org', 'niche.com', 'har.com', 'usnews.com', 'publicschoolreview.com', \n",
    "             'nces.ed.gov', 'dnb.com', 'schooldigger.com', 'elementaryschools.org', 'closelocation.com']\n",
    "\n",
    "# Define search metadata\n",
    "school_name = 'Dr. David C. Walker Intermediate School'\n",
    "school_address = '6500 Ih 35 N Ste C, San Antonio, TX 78218'\n",
    "#school_name = \"River City Scholars Charter Academy\"\n",
    "#school_address = \"944 Evergreen Street, Grand Rapids, MI 49507\"\n",
    "\n",
    "# Collect search results\n",
    "urls = search(school_name + ' ' + school_address, \\\n",
    "              stop=20, pause=5.0) # Expand search range to help avoid excluded domains\n",
    "print(\"Successfully collected Google search results.\")\n",
    "\n",
    "# Initialize exclusions match counter: How many excluded domains has this search encountered?\n",
    "excluded_num = 0 \n",
    "\n",
    "# Loop through google search output to find first good result:\n",
    "for url in urls:\n",
    "    if any(domain in url for domain in exclusions):\n",
    "        print(f'Bad site detected: {url}') \n",
    "        excluded_num += 1 # Add one to exclusions match counter\n",
    "    else:\n",
    "        good_url = url\n",
    "        print(\"Success! URL obtained by Google search with \" + str(excluded_num) + \" bad URLs avoided.\")\n",
    "        break # Exit for loop after first good url is found\n",
    "        \n",
    "print(f'Quality URL: {good_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of [the \"quality\" URL we landed on](https://yellow.place/en/dr-david-c-walker-int-san-antonio-tx-usa)? What does this mean about our exclusion list?\n",
    "\n",
    "### Challenge\n",
    "\n",
    "Improve our automated searching to try to get the genuine URL of Dr. David C. Walker Intermediate School. <br/>\n",
    "_Hint_: You could try (A) adding more URLs to the exclusions list OR (B) try a simple search but for more URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully collected Google search results.\n",
      "Bad site detected: https://www.niche.com/k12/dr-david-c-walker-intermediate-school-san-antonio-tx/\n",
      "Bad site detected: https://www.mapquest.com/us/texas/dr-david-c-walker-intermediate-school-438581037\n",
      "Bad site detected: https://www.usnews.com/education/k12/texas/dr-david-c-walker-elementary-206298\n",
      "Bad site detected: https://www.greatschools.org/texas/san-antonio/12035-Dr-David-C-Walker-Intermediate-School/\n",
      "Bad site detected: https://yellow.place/en/dr-david-c-walker-int-san-antonio-tx-usa\n",
      "Bad site detected: https://elementaryschools.org/directory/tx/cities/san-antonio/dr-david-c-walker-elementary/480006211404/\n",
      "Bad site detected: https://www.publicschoolreview.com/dr-david-c-walker-elementary-school-profile\n",
      "Bad site detected: https://www.schoolsnearme.net/en/public/dr-david-c-walker-elementary/79869\n",
      "Bad site detected: https://closelocation.com/find-school/dr-david-c-walker-elementary-school-school-in-basse-basse-16-11508-1216-80\n",
      "Bad site detected: https://www.homefacts.com/schools/Texas/Bexar-County/San-Antonio/Dr-David-C-Walker-El.html\n",
      "Success! URL obtained by Google search with 10 bad URLs avoided.\n",
      "Quality URL: https://www.donorschoose.org/schools/texas/school-of-excellence-in-education/dr-david-walker-elementary-school/95612\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "# Option A: Define expanded exclusions\n",
    "exclusions = ['facebook.com', 'greatschools.org', 'niche.com', 'har.com', 'usnews.com', 'publicschoolreview.com', \n",
    "              'nces.ed.gov', 'dnb.com', 'schooldigger.com', 'elementaryschools.org', 'closelocation.com', \n",
    "              'castro.tea.state.tx.us', 'yellow.place', 'trueschools.com', 'mapquest.com', 'schoolsnearme.net', \n",
    "              'homefacts.com']\n",
    "\n",
    "# Collect search results\n",
    "urls = search(school_name + ' ' + school_address, \\\n",
    "              stop=20, pause=5.0) # Expand search range to help avoid exclusionsed domains\n",
    "print(\"Successfully collected Google search results.\")\n",
    "\n",
    "# Initialize exclusions match counter\n",
    "excluded_num = 0 \n",
    "\n",
    "# Get first good search result:\n",
    "for url in urls:\n",
    "    if any(domain in url for domain in exclusions):\n",
    "        print(f'Bad site detected: {url}') \n",
    "        excluded_num += 1 # Add one to exclusions match counter\n",
    "    else:\n",
    "        good_url = url\n",
    "        print(\"Success! URL obtained by Google search with \" + str(excluded_num) + \" bad URLs avoided.\")\n",
    "        break # Exit for loop after first good url is found\n",
    "        \n",
    "print(f'Quality URL: {good_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.niche.com/k12/dr-david-c-walker-intermediate-school-san-antonio-tx/\n",
      "https://www.mapquest.com/us/texas/dr-david-c-walker-intermediate-school-438581037\n",
      "https://www.usnews.com/education/k12/texas/dr-david-c-walker-elementary-206298\n",
      "https://www.greatschools.org/texas/san-antonio/12035-Dr-David-C-Walker-Intermediate-School/\n",
      "https://yellow.place/en/dr-david-c-walker-int-san-antonio-tx-usa\n",
      "https://elementaryschools.org/directory/tx/cities/san-antonio/dr-david-c-walker-elementary/480006211404/\n",
      "https://www.publicschoolreview.com/dr-david-c-walker-elementary-school-profile\n",
      "https://www.schoolsnearme.net/en/public/dr-david-c-walker-elementary/79869\n",
      "https://closelocation.com/find-school/dr-david-c-walker-elementary-school-school-in-basse-basse-16-11508-1216-80\n",
      "https://www.homefacts.com/schools/Texas/Bexar-County/San-Antonio/Dr-David-C-Walker-El.html\n",
      "https://www.donorschoose.org/schools/texas/school-of-excellence-in-education/dr-david-walker-elementary-school/95612\n",
      "https://texas.hometownlocator.com/schools/profiles,n,dr%20david%20c%20walker%20elementary,z,78218,t,pb,i,1115128.cfm\n",
      "https://wheretoteach.com/dr-david-c-walker-elementary-22789\n",
      "http://www.localschooldirectory.com/public-school/345352660/TX\n",
      "https://texas.legacytraditional.org/walker/\n",
      "http://www.loresult.com/us-zip-codes/united-states-texas-tx-78218/\n",
      "https://www.rockethomes.com/homes/5267-prince-valiant-san-antonio-tx-78218\n",
      "https://rehold.com/San+Antonio+TX/GOLFCREST+DR/602\n",
      "https://magnetschools.us/county/bexar_tx\n",
      "https://nces.ed.gov/globallocator/index.asp?search=1&State=TX&city=San+Antonio&zipcode=78201&School=1&PrivSchool=1&miles=15\n"
     ]
    }
   ],
   "source": [
    "# Option B: Expanded simple search\n",
    "for url in search(school_name + ' ' + school_address, \\\n",
    "                  stop=20, pause=5.0, num=20): # Get first 20 results: stop at 20, and get 20 in first page of results\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, David C. Walker Intermediate School closed recently; that's why Google doesn't find what used to be its [official website](https://excellence-sa.org/walker/) (though you could probably find this on the Internet Archive's Wayback Machine). How could we avoid such blocks in the future? You could use your expanded exclusion list and if no quality URL appears in the first 10 results, consider the school closed. How else could you do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making `Requests` <a id='request'></a>\n",
    "\n",
    "### Challenge\n",
    "\n",
    "Get the HTML for [this claim review by fact checking site PolitiFact](https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/). \n",
    "Print out the first 1000 characters and compare it to the HTML you see when you view the source HTML in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<!DOCTYPE html>\\n<html lang=\"en-US\" dir=\"ltr\">\\n<head>\\n<meta charset=\"utf-8\">\\n<meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n<title>PolitiFact | Citizens United calls Biden’s infrastructure plan the Green New Deal. It isn’t.</title>\\n<meta name=\"description\" content=\"Republican opposition to President Joe Biden’s infrastructure proposal has been swift and vocal. Senate Minority Leader \" />\\n<meta property=\"og:url\" content=\"https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/\" />\\n<meta property=\"og:image\" content=\"https://static.politifact.com/politifact/rulings/meter-mostly-false.jpg\" />\\n<meta property=\"og:image:secure_url\" content=\"https://static.politifact.com/politifact/rulings/meter-mostly-false.jpg\" />\\n<meta property=\"og:title\" content=\"PolitiFact - Citizens United calls Biden’s infrastructure plan the Green New Deal. It isn’t.\" />\\n<meta propert'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "import requests \n",
    "\n",
    "url = 'https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/'\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "html[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing HTML <a id='parsing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty parsing with `BeautifulSoup` <a id='BS'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Find all the links in the above claim review page using the `<a>` tags and their `href` elements. Print every 10th link. What do you notice about where these links point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup for parsing\n",
    "from bs4 import BeautifulSoup\n",
    "import requests # for making web requests\n",
    "\n",
    "url = 'https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/'\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text)\n",
    "\n",
    "# solution\n",
    "for link in soup.find_all('a')[::10]: # every 10th element\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see lots of relative links (e.g., `/pennsylvania/`), places where the `href` seems to point nowhere (e.g., `#`), and communication shortcuts (e.g., `https://twitter.com/share?text=PolitiFact - Citizens United calls...`). This could be cleaned up by appending relative links to the domain name (`https://www.politifact.com/`) and keeping only URLs (and nothing after)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting human-readable text <a id='readable'></a>\n",
    "\n",
    "Not all websites use the `<p>` tag to indicate the important, human-readable text. Sometimes we need to approach HTML parsing from the other end: By finding and removing all non-informative tags. Let's use `BeautifulSoup` to build such a method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Use `decompose()` to remove from the soup all tags showing anything other than human-readable text. Below is a list of such junk tags to use as an exclusion list.\n",
    "\n",
    "```\n",
    "\"b\", \"big\", \"i\", \"small\", \"tt\", \"abbr\", \"acronym\", \"cite\", \"dfn\", \"kbd\", \n",
    "\"samp\", \"var\", \"bdo\", \"map\", \"object\", \"q\", \"span\", \"sub\", \"sup\", \"head\", \n",
    "\"title\", \"[document]\", \"script\", \"style\", \"meta\", \"noscript\"\n",
    "```\n",
    "\n",
    "_Hint:_ Iterate over these tags to identify each one in the soup and remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "\n",
    "# Define inline tags for cleaning out HTML\n",
    "tags_exclusions = [\"b\", \"big\", \"i\", \"small\", \"tt\", \"abbr\", \"acronym\", \"cite\", \"dfn\", \"kbd\", \n",
    "                  \"samp\", \"var\", \"bdo\", \"map\", \"object\", \"q\", \"span\", \"sub\", \"sup\", \"head\", \n",
    "                  \"title\", \"[document]\", \"script\", \"style\", \"meta\", \"noscript\"]\n",
    "\n",
    "# Get HTML and then soup\n",
    "url = 'https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/'\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text)\n",
    "\n",
    "# Remove non-visible tags from soup with two for-loops:\n",
    "for tag in tags_exclusions:\n",
    "    for elem in soup.find_all(tag):\n",
    "        elem.decompose()\n",
    "        \n",
    "# Show result\n",
    "visible = soup.get_text(strip=True)\n",
    "print(visible[1000:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that word boundaries get clobbered when you call `get_text()`. This is because the default setting for this method is `strip=True`, which tells `BeautifulSoup` to strip whitespaces (of any kind) from the beginning and end of each bit of text. Using `strip=False` leads to lots of extra whitespaces--usually, newlines--which requires some regular expressions to clean up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Using the above tags exclusion list and `decompose()` as before, this time use the `strip=False` parameter when calling `get_text()` to avoid combining words across whitespace boundaries. Instead, use regular expressions to clean up extra whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "\n",
    "url = 'https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/'\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text)\n",
    "\n",
    "# Faster way to remove non-visible tags from soup:\n",
    "[s.decompose() for s in soup(tags_exclusions)]\n",
    "\n",
    "# Don't strip spaces in-between elements, to avoid clobbering word boundaries\n",
    "visible = soup.get_text(strip=False)\n",
    "\n",
    "import re\n",
    "#visible = re.sub(r\"\\n+\", \"\\n\", visible) # This works, but less extensible than below\n",
    "\n",
    "import regex # better unicode support than Python's built-in re package\n",
    "\n",
    "# Use regex to replace all consecutive spaces (including in unicode), tabs, or \"|\"s with a single space\n",
    "visible = regex.sub(r\"[ \\t\\h\\|]+\", \" \", visible)\n",
    "# Replace any consecutive linebreaks with a single space\n",
    "visible = regex.sub(r\"[\\n\\r\\f\\v]+\", \"\\n\", visible)\n",
    "\n",
    "print(visible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Challenge\n",
    "\n",
    "You might have noticed that when we scraped HTML above from [this claim review by PolitiFact](https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/), we got headers and tags like this:\n",
    "```html\n",
    "<p>Misinformation isn't going away just because it's a new year. Support trusted, factual information with a tax deductible contribution to PolitiFact.</p>\n",
    "<p>\n",
    "<a class=\"m-disruptor-content__link\" href=\"/membership/\">More Info</a>\n",
    "</p>\n",
    "<p class=\"c-image__caption-inner copy-xs\">\n",
    "The White House infrastructure plan has $111 billion to improve water and sewer systems. (Shutterstock)\n",
    "</p>\n",
    "```\n",
    "Use what you now know about identifying HTML, removing tags, and cleaning spacing to scrape a clean explanation from the body of this article. \n",
    "\n",
    "_Hint:_ Use your browser to inspect this website's HTML and identify any unique types and/or classes that enclose the explanation (and nothing else)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "\n",
    "# Set URL to scrape\n",
    "url = 'https://www.politifact.com/factchecks/2021/apr/02/citizens-united/citizens-united-calls-bidens-infrastructure-plan-g/'\n",
    "\n",
    "# Scrape HTML with requests and beautifulsoup\n",
    "html = requests.get(url) \n",
    "soup = BeautifulSoup(html.text)\n",
    "\n",
    "explanation = soup.find('article', class_='m-textblock').get_text() # identify this class from looking at HTML\n",
    "\n",
    "import re\n",
    "explanation = re.sub(r\"\\n+\", \"\\n\", explanation)\n",
    "\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the output from this focused, site-specific scraping approach with that from the exclusion list method above. <br/>\n",
    "**Which method gives the cleaner output? Which method is more extensible?**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
