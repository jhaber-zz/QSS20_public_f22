{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import plotnine \n",
    "from plotnine import *\n",
    "import yaml\n",
    "\n",
    "## note: you may need to install these using !pip install\n",
    "import census\n",
    "from census import Census\n",
    "import us\n",
    "from us import states\n",
    "import mysql.connector\n",
    "\n",
    "## sklearn imports\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## print mult things\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "def load_creds(path: str):\n",
    "    with open(path, 'r') as stream:\n",
    "        try:\n",
    "            creds = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return(creds)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs, SQL, and Supervised Machine Learning (56 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a wrapper function to pull data from the NAEP API (12 points)\n",
    "\n",
    "In the class activity here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/07_apispart1_examplecode_blank.ipynb \n",
    "\n",
    "We practiced pulling from the NAEP API. We pulled a small amount of data at the national level (writing scores by gender) using a query where the parameters were hardcoded.\n",
    "    \n",
    "In this problem, we'll practice pulling a larger set of data and writing a wrapper function.\n",
    "    \n",
    "As a reminder, the documentation for the NAEP API is here: https://www.nationsreportcard.gov/api_documentation.aspx\n",
    "\n",
    "The base link for writing queries to that API is: https://www.nationsreportcard.gov/Dataservice/GetAdhocData.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Write a query to pull 8th-grade mathematics scores in 2015 from California by gender (1 point)\n",
    "\n",
    "- Subject: mathematics \n",
    "- Subscale: MRPCM composite scale \n",
    "- Grade: 8\n",
    "- Year: 2015\n",
    "- grouping variable: GENDER \n",
    "\n",
    "Print the output in dataframe format and briefly interpret; what do scores look like between the genders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Write a query to pull 8th-grade mathematics scores in 2013, 2015, 2017, and 2019 from California by gender (1 point)\n",
    "\n",
    "Same as 1.1 but pull the years 2013, 2015, 2017, and 2019 (search documentation for how to combine) in one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create a line plot to show variation in the scores across years (2 points)\n",
    "\n",
    "Using the results from 1.2, create a plot where the x axis has the year and the y axis is the math scores (`value` in dataframe), and there are separate lines/colors for male versus female students\n",
    "\n",
    "Start the limits of the y axis at 270 and add informative labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Reproduce the queries from 1.1 and 1.2 using a user-defined function (4 points)\n",
    "\n",
    "Create a function, `construct_naep_query` that takes in two arguments:\n",
    "\n",
    "- year: this should be a list with all years (so if one year, single element list; if multiple years, list with those years)\n",
    "- place: this should be a string with the name of the state or jurisdiction to pull \n",
    "    \n",
    "Have the function return the query and make sure it's identical to the queries you wrote for 1.1 and 1.2 (can use assert or other checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to execute function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Write and execute user-defined function that takes in a query and returns a pandas dataframe with the content of the response (4 points)\n",
    "\n",
    "- Write a user-defined function (`process_naep_query`) that takes in the NAEP query as a string, calls the API, and transforms the response into a pandas dataframe. Have the function return that pandas dataframe\n",
    "\n",
    "- Make sure the function is flexible enough to handle queries that return an error; for queries that return an error, have the function return the string \"Data not found; check your query\"\n",
    "\n",
    "- Execute the function on the query that pulls 2013-2019 data (either from handwriting the query or the result in 1.4)\n",
    "\n",
    "- Print the resulting dataframe\n",
    "\n",
    "- Then execute the function on a query that pulls a state that doesn't exist (call this state ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore data using SQL queries (18 points)\n",
    "\n",
    "In the previous example, you worked with the data in a flat file and manipulated it using pandas. Here, we're going to practice running queries to do some calculations using SQL --- in the case of our data, this is a bit overkill since the data are small but it is practice for larger datasets.\n",
    "\n",
    "Database name: `math_gencompare`\n",
    "\n",
    "**Resources for these problems**: \n",
    "\n",
    "- Example code: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/10_SQL_examplecode.ipynb \n",
    "- Activity solutions: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/10_SQL_activity_solutions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load database credentials if haven't already and establish a connection (1 point)\n",
    "\n",
    "Note: you need to be on `eduroam` or `VPN` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run a query to select all columns and the first 5 rows of the math_gencompare database to explore structure (2 points)\n",
    "\n",
    "Read the results in as a pandas dataframe and print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Find the (1) number of rows in the database, (2) number of distinct states,  (3) number of distinct years (3 points)\n",
    "\n",
    "Interpret the results - how do you think the data is structured in terms of states and years (eg long format where each state repeated; wide format)?\n",
    "\n",
    "**Hint**: rather than using count `(*)` for the latter two, think about the `distinct` command in combination with `count`: https://www.w3resource.com/mysql/aggregate-functions-and-grouping/aggregate-functions-and-grouping-count-with-distinct.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Construct a new variable, `is_male_higher` that takes the value of 1 if the math scores of males exceed that of females in that state and year (each row) (2 points)\n",
    "\n",
    "Read in the results, print the head, and find the mean across all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 group by year and find the percentage of states where male scores are higher than females (4 points)\n",
    "\n",
    "**A.** Write a query that (1) groups by year and (2) finds the percentage of states that have higher scores for males than females in this year \n",
    "\n",
    "**B.** Print the resulting dataframe and interpret the results \n",
    "\n",
    "Hint: can either use subquery to construct the `is_male_higher` and use it or do it all in one query with a comparison; the `avg` command is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 group by state and find the percentage of years where male scores higher than females\n",
    "\n",
    "A. Write a query that (1) groups by state and (2) finds the percentage of years that have higher scores for males than females in that state\n",
    "\n",
    "B. Plot the results ordering the states from males higher all 4 years to males higher none of the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Use a subquery to create an indicator and group by that indicator (6 points)\n",
    "\n",
    "The following states were the first 6 to expand the right to vote to women before the uniform federal expansion in 1920\n",
    "\n",
    "- Wyoming 1890\n",
    "- Colorado 1893\n",
    "- Utah 1896\n",
    "- Idaho 1896\n",
    "- Washington 1910\n",
    "- California 1911\n",
    "\n",
    "**A.** Create an indicator `is_early_vote` for whether a state is in that list or not; do so without typing the state names inside the string and instead collapsing the list of states we provide and using something like `format`. Hint on how to combine the state names while preserving the quotes around each: https://stackoverflow.com/questions/12007686/join-a-list-of-strings-in-python-and-wrap-each-string-in-quotation-marks \n",
    "\n",
    "**B.** Then, group by the `is_early_vote` indicator and `year` and find the percencentage of states in each group where males had higher scores than females \n",
    "\n",
    "**C.** Print the resulting dataframe and interpret. Does early expansion of voting seem to be correlated with girls scoring better on the math tests a century later?\n",
    "\n",
    "Hint: in order to group by the indicator in step b, you may need to use a subquery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of states we provide\n",
    "list_suffrage = [\"Wyoming\", \"Colorado\", \"Utah\", \"Idaho\", \"Washington\", \n",
    "                \"California\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code starts here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pull state-level attributes using Census API (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Obtain a Census API key, place it in credentials yaml, load the yaml file, and initialize connection to Census API using the `census` package  (0 points)\n",
    "\n",
    "- Obtain a census API key from here: https://api.census.gov/data/key_signup.html \n",
    "- Place it in a credentials yaml file (feel free to name the key whatever; can be in same yaml file as the database credentials or different one)\n",
    "- Load the credentials file with the key\n",
    "- Documentation here for the `census` package on establishing an API connection: https://github.com/datamade/census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run this function (feeding it your api connection) to get a list of variables to pull (0 points)\n",
    "\n",
    "Feed the connection to the API you created in previous step (if you print type it's a census.core.Census class) to the `your_connection` argument in the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep in blank\n",
    "to_pull = ['RATIO OF INCOME TO POVERTY LEVEL OF FAMILIES IN THE PAST 12 MONTHS',\n",
    "          'ALLOCATION OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS - PERCENT OF INCOME ALLOCATED',\n",
    "          'MEDIAN HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2018 INFLATION-ADJUSTED DOLLARS)',\n",
    "          'EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER',\n",
    "          'HOUSEHOLD TYPE (INCLUDING LIVING ALONE) BY RELATIONSHIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep in blank\n",
    "def get_acs_varnames(your_connection):\n",
    "    \n",
    "    ## get tables for the acs 5-year estimates\n",
    "    all_tables = pd.DataFrame(your_connection.acs5.tables())\n",
    "    \n",
    "    ## specify the ones to pull\n",
    "    info_topull = all_tables[all_tables.description.isin(to_pull)].copy()\n",
    "    \n",
    "    ## use raw api to get varnames within those tables\n",
    "    all_vars = [pd.DataFrame(requests.get(one_table).json()['variables']).T\n",
    "                for one_table in info_topull.variables]\n",
    "    all_vars_df = pd.concat(all_vars)\n",
    "    all_vars_df['varname'] = all_vars_df.index\n",
    "    \n",
    "    ## subset to relevant\n",
    "    all_vars_df_subset = all_vars_df[['varname', 'group', 'label',\n",
    "                                    'concept']].copy()\n",
    "    all_vars_df_est = all_vars_df_subset[all_vars_df.varname.str.contains(\"E$\", \n",
    "                                        regex = True)].copy()\n",
    "    return(all_vars_df_est)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: replace the your_connection with your \n",
    "## connection to the Census API\n",
    "acs_cols = get_acs_varnames(your_connection)\n",
    "acs_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Use the Census API to pull the demographic variables for all 50 states (8 points)\n",
    "\n",
    "**A.** Use list comprehension to pull the variables in the `varname` column of the above data for every state (each FIPS code) using the `acs5.state` method for the year 2013.\n",
    "- Hint: See the documentation for how to feed it variables to pull (requires a tuple); the documentation shows an example state--`MD`. You can find the other `FIPS` Ccodes for states in the `states` object in `us` package you loaded above): https://github.com/datamade/census/blob/70e2c08710c1e10e5bc2054b78613fa8794d4765/README.rst\n",
    "\n",
    "**Note**: this takes ~1-2 minutes to run on our machine\n",
    "\n",
    "**B.** Transform the result (which is a list of json) into a list of dataframes. Then concatenate into one dataframe and melt on `state` so that each state is repeated across variables\n",
    "\n",
    "**C.** Then, merge the result from step B first with the `all_states_fips` df, then merge that with `acs_cols` data from 3.2 (on varname and variable) to know both which states the variables correspond to and the more informative variable names \n",
    "\n",
    "Call the final output `acs_df_forperc` so you can run the next code we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this code\n",
    "## NOTE: you need to have the us package\n",
    "## installed and imported\n",
    "cols_pull = tuple(acs_cols.varname)\n",
    "all_states = states.STATES\n",
    "all_states_fips = pd.DataFrame({'FIPS':\n",
    "                    [one_state.fips for one_state in all_states],\n",
    "                    'state': [one_state.name for one_state in all_states],\n",
    "                'abbrev': [one_state.abbr for one_state in all_states]})\n",
    "all_states_fips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here for remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 run code to transform counts into percentages (0 points)\n",
    "\n",
    "- Run the following code to transform the ACS counts in `acs_df_forperc` into percentages\n",
    "\n",
    "Note: You may see a warning from the str.split step; feel free to ignore it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentages(df, name_estimatecol = 'estimate'):\n",
    "    \n",
    "    ## remove cols that dont need percentages\n",
    "    df_forperc = df[~df.perc_NA].copy()\n",
    "    \n",
    "    ## sort by \n",
    "    \n",
    "    ## group by location and variable prefix \n",
    "    group_co_tract_varg = df_forperc.groupby(['FIPS', 'variable_prefix'])\n",
    "    \n",
    "    ## iterate over groups\n",
    "    df_longperc = []\n",
    "    for group, data_raw in group_co_tract_varg:\n",
    "        prefix = data_raw.variable_prefix.iloc[0]\n",
    "        FIPS = data_raw.FIPS.iloc[0]\n",
    "        row_list_group = []\n",
    "        data = data_raw.sort_values(by = 'variable_suffix')\n",
    "        for i in range(1, data.shape[0]):\n",
    "            numerator = data[name_estimatecol].iloc[i]\n",
    "            denominator = float(data[name_estimatecol].iloc[0])\n",
    "            if denominator == 0:\n",
    "                denominator = np.nan\n",
    "            if denominator != 0:\n",
    "                percentage = numerator / denominator\n",
    "                row = [prefix, FIPS]\n",
    "                row = row + [data.variable_suffix.iloc[i], percentage]\n",
    "                row_list_group.append(row)\n",
    "        df_longperc.append(pd.DataFrame(row_list_group))\n",
    "    percentages_all_groups = pd.concat(df_longperc)\n",
    "    percentages_all_groups.columns = ['variable_prefix',\"FIPS\",\n",
    "                                  'variable_suffix', 'percentage']\n",
    "    percentages_all_groups['percentage'] = percentages_all_groups.percentage.astype(float)\n",
    "    return(percentages_all_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_percnotrelevant = [\"B19013_001E\"]\n",
    "\n",
    "## create prefix and suffix columns\n",
    "acs_df_forperc['variable_prefix'], acs_df_forperc['variable_suffix'] = \\\n",
    "                                acs_df_forperc['varname'].str.split('_', 1).str\n",
    "acs_df_forperc['perc_NA'] = np.where(acs_df_forperc.varname.isin(varnames_percnotrelevant),\n",
    "                                  True, False)\n",
    "acs_df_forperc = acs_df_forperc[acs_df_forperc.variable != \"GEO_ID\"].copy()\n",
    "\n",
    "perc_long = create_percentages(acs_df_forperc, 'value').sort_values(by = 'variable_prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_long_wnames = pd.merge(perc_long,\n",
    "                           acs_df_forperc,\n",
    "                           on = ['variable_prefix', 'variable_suffix', 'FIPS'],\n",
    "                           how = \"right\")\n",
    "perc_long_wnames['value'] = perc_long_wnames.value.astype(float)\n",
    "\n",
    "perc_long_wnames['percentage'] = np.where(perc_long_wnames.perc_NA,\n",
    "                                         perc_long_wnames.value,\n",
    "                                         perc_long_wnames.percentage)\n",
    "perc_long_wnames['varname_words'] = \"acspredict_\" + perc_long_wnames.concept.str.replace(\"\\s+|\\(|\\)\", \"_\", \n",
    "                                    regex = True).str.lower() + \\\n",
    "                            perc_long_wnames.label.str.replace(\"\\.|\\!|\\,|\\(|\\)|\\-\", \n",
    "                                    \"\", regex = True).str.lower() \n",
    "\n",
    "perc_long_wnames_final = perc_long_wnames[['FIPS', 'percentage', \n",
    "                                          'varname_words']].copy()\n",
    "\n",
    "\n",
    "perc_wide = pd.pivot_table(perc_long_wnames_final, \n",
    "                           index = 'FIPS',\n",
    "                          columns='varname_words',\n",
    "                            values='percentage').reset_index()\n",
    "\n",
    "## merge state info back on\n",
    "perc_wide_wstate = pd.merge(perc_wide,\n",
    "                           all_states_fips,\n",
    "                           on = \"FIPS\",\n",
    "                           how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_wide_wstate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 extra credit (2 points)\n",
    "\n",
    "Use list comprehension and NAEP query creation/process results functions you created above to iterate over state abbreviations in `all_states_fips` and pull the same test score gap information\n",
    "\n",
    "If skipping, you'll read in pkl at next step\n",
    "\n",
    "**Note**: this took 2 mins to run on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore variation in math score disparities and trends (18 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Read in the `acs_wmath.pkl` file (csv is backup) (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create a visualization where one axis is the state; the other axis is the male 2013 math scores - the female 2013 math scores (gender disparity) (2 points)\n",
    "\n",
    "\n",
    "You have free rein over additional details but make sure it is informative over what direction of disparity positive versus negative values mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Examine gender disparity in relation to household income (6 points)\n",
    "\n",
    "**A.** Construct an indicator variable for the state having better performance of males in 2013 than females\n",
    "\n",
    "**B.** First plot a smoothed scatterplot of estimated median household income from the acs data (we provide varname below) vs `math_male_2013`. Then do a second smoothed scatterplot for median household income vs `math_female_2013`.\n",
    "\n",
    "**C.** \n",
    "Then use the `np.corrcoef` command (three separate times) to examine the bivariate correlation of\n",
    "- male performance\n",
    "- female performance\n",
    "- the indicator variable from **A** \n",
    "\n",
    "with median household income (`acspredict_median_household_income_in_the_past_12_months__in_2018_inflation-adjusted_dollars_estimatemedian household income in the past 12 months in 2018 inflationadjusted dollars`)\n",
    "\n",
    "Documentation: https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "\n",
    "**D.** Interpret the correlations - in states with higher median household income (MHI), do \n",
    "   - boys tend to perform better than boys in states with lower MHI?\n",
    "   - girls tend to perform better than girls in states with lower MHI?\n",
    "   - boys tend to outperform girls more than they do in states with lower MHI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Predicting disparities (10 points)\n",
    "\n",
    "**A.** Read in the raw `acs_wmath` data again (so loses the variables you created above)\n",
    "\n",
    "**B.** Construct a binary indicator variable for male score > female score  for each year - for full credit, do so without repeating the difference code for each of the four years: name these according to following convention: `outcome_male_higher_female_year` where year is 2013, 2015, 2017, or 2019 (e.g., 2013: `outcome_male_higher_female_2013`). After this, remove the raw math scores as columns in the data (so filter out any column with the word math)\n",
    "\n",
    "**C.** Melt the data (`acs_wmath`) to long where instead of wide years, years are repeated within state; the acs vars will also be repeated since we only pulled one year \n",
    "\n",
    "**D.** Split into train-test split at state level (so all years in same state -> either all in train or all test). Randomize 35 states to train; 15 states in test. \n",
    "\n",
    "**E.** Normalize the features to mean 0, variance 1 and estimate a **decision tree with a max depth of 5**. \n",
    "\n",
    "**F.** Interpret the feature importances\n",
    "\n",
    "**G.** Evaluate the precision and recall of that model in the test set states without using the `score`, `precision`, or `recall` functions in sklearn. Briefly interpret: compared to our class example (a high-dimensional feature matrix of yelp reviews with ~15000 observations), why do you think our models perform worse for this set of data/predictors?\n",
    "\n",
    "Resources: \n",
    "-https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/09_binaryclassification_activity_solutions.ipynb\n",
    "\n",
    "- Feature normalization: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "- Definition of precision and recall: https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
