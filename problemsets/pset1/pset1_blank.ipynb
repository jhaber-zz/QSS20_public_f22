{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698a2cf8",
   "metadata": {},
   "source": [
    "# 0. Problem set 1 (42 points)\n",
    "\n",
    "This problem set will:\n",
    "\n",
    "- Make sure your jupyter notebook installation is working\n",
    "- Give you practice with the following basic Python concepts covered in lecture (and optionally on DataCamp):\n",
    "  - Python lists\n",
    "  - Basic list comprehension\n",
    "- Give you practice loading in and interpreting the Cook County, Illinois (which contains Chicago) sentencing dataset. \n",
    "  - This dataset reports the sentence given to defendants convicted of different crimes. \n",
    "  - [The data codebook is available here](https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf). For the latest on this data (for future reference), [see the official website](https://datacatalog.cookcountyil.gov/Courts/Sentencing/tg8v-tm6u).\n",
    "- Give you practice wrangling that data using Pandas (groupby, filtering, apply, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e9e34",
   "metadata": {},
   "source": [
    "# 1. Python practice (total 14 points)\n",
    "\n",
    "## 1.1 Practice with lists\n",
    "\n",
    "### 1.1.1 List addition (2 points)\n",
    "We provide you with a list of our names below.\n",
    "\n",
    "- Use list addition to add your name to the list\n",
    "- Store this as a new list called `instructor_my_name`\n",
    "- Print that list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835fec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of instructor names\n",
    "instructor_names = ['Eunice', 'Jaren', 'Ramsey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to store and print list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d705da",
   "metadata": {},
   "source": [
    "### 1.1.2 List indexing (2 points)\n",
    "\n",
    "- Use the `.index()` method to get the index of the professor's name (Jaren)\n",
    "- Use that index to extract that name\n",
    "- Store it in a list called `prof` and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7899dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to get index of prof's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to extract the name and print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e7e9e",
   "metadata": {},
   "source": [
    "### 1.1.3 Indexing lists of lists (2 points)\n",
    "\n",
    "We provide you with the below list of lists (`roles_listoflists`).\n",
    "\n",
    "- Use subsetting to pull out the role of Jaren (can just hard code the relevant indices)\n",
    "- Pull out and print the type of the element at index 1 (Eunice's name and role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf70574",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of names and roles\n",
    "roles_listoflists = [['Jaren', 'Prof'], ['Eunice', 'TA'], ['Ramsey', 'Tutor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to pull out role of jaren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to pull out and print the type at index 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d2820",
   "metadata": {},
   "source": [
    "### 1.1.4 Edit list elements (2 points)\n",
    "\n",
    "- In `roles_listoflists`, replace the role 'TA' with the role 'Teaching Assistant' (fine to do in two lines of code)\n",
    "- Print the updated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36536f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to replace role text and print updated list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f462b5",
   "metadata": {},
   "source": [
    "## 1.2. Practice with list comprehension\n",
    "\n",
    "Here, we provide you with a list containing the course codes for a few Dartmouth College Fall 2022 courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0878c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## course code list \n",
    "course_codes = [\"QSS 20\", \"QSS 17\", \"COSC 1\", \"GOV 10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc7230",
   "metadata": {},
   "source": [
    "### 1.2.1 Using list comprehension to keep all elements / transform them (2 points)\n",
    "\n",
    "- Create a new list, `course_codes_ns`, that removes the spaces in each course code: e.g., 'QSS 20' should become 'QSS20'\n",
    "- Print `course_codes_ns`\n",
    "\n",
    "*Hint*: If you're new to regular expressions, then use a built-in string method: `str.replace()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1413620",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to create list without spaces and print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9a87e",
   "metadata": {},
   "source": [
    "### 1.2.2 Using list comprehension to subset a list (2 points)\n",
    "\n",
    "- Using `course_codes_ns`, create a new list just with courses with 'QSS' in the name; store it as `course_codes_qss`\n",
    "\n",
    "*Hint*: Use an 'if' statement in the list comprehension to implement the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to create and store new QSS-specific list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a960516",
   "metadata": {},
   "source": [
    "### 1.2.3 Using list comprehension to conditionally change a list's elements (2 points)\n",
    "\n",
    "- using `course_codes_ns`, add the string prefix \"coding_\" to COSC 1 and QSS 20; \"stats_\" to GOV 10 and QSS 17\n",
    "- Store as `course_codes_detail` and print\n",
    "\n",
    "*Hint*: You can implement an if-else statement in a list comprehension (\"conditional transformation\") with this syntax:\n",
    "```python\n",
    "[elem_transform1 if condition else elem_transform2 for elem in lst]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to add prefixes, store, and print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00117fe6",
   "metadata": {},
   "source": [
    "# 2. Cleaning and interpreting the sentencing dataset (total 28 points)\n",
    "\n",
    "## 2.0 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "## for plotting; can also use seaborn\n",
    "## note: for plotnine, you likely need to install using pip or conda\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## datetime util\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbf3e2",
   "metadata": {},
   "source": [
    "## 2.1 Load the data (0 points)\n",
    "\n",
    "Use `pd.read_csv` to load the `sentencing_asof0405.csv` data (make sure to unzip the `pset2_inputdata` folder and not hard code your user-specific path name)\n",
    "\n",
    "*Notes*: You may receive a warning about mixed data types upon import; feel free to ignore, or call `low_memory=False` as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "## plotting\n",
    "## note: you likely need to install this using\n",
    "## pip or conda; you can delete this line\n",
    "## if you're using matplotlib, seaborn, or other\n",
    "## plotting pkg\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## datetime util\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4750cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f288247",
   "metadata": {},
   "source": [
    "## 2.2 Inspect the data (0 points)\n",
    "\n",
    "Print the head, dimensions, and info for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8578c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e100cce",
   "metadata": {},
   "source": [
    "## 2.3: Understanding the unit of analysis (5 points)\n",
    "\n",
    "\n",
    "### 2.3.1 Print the number of unique values for the following columns all at once (e.g., with `.apply()`), i.e. without copying/pasting code to do each one separately:\n",
    "\n",
    "- Cases (CASE_ID)\n",
    "- People (CASE_PARTICIPANT_ID)\n",
    "- Charges (CHARGE_ID)\n",
    "\n",
    "**Source for this question**: [slide 14 here on column-wise apply](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/02_qss20_fa22_pandas.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here printing numbers of unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d5298",
   "metadata": {},
   "source": [
    "### 2.3.2  Cases and people\n",
    "\n",
    "You might have noticed there are more unique people than unique cases and more unique charges than unique people. This is because the same case can have multiple people involved, and the same person can have multiple charges tied to a case. Illustrate this by showing:\n",
    "   \n",
    "- an example of a case involving multiple people\n",
    "- an example of a person in a case involving multiple charges\n",
    "\n",
    "**Resources**: groupby and agg covered in:\n",
    "- [The in-class activity on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/00_pandas_datacleaning_blank.ipynb) and [solutions](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/00_pandas_datacleaning_solutions.ipynb)\n",
    "\n",
    "- [These lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/02_qss20_fa22_pandas.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here showing a case with multiple people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d820e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here showing a case with multiple charges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0f875",
   "metadata": {},
   "source": [
    "### 2.3.3 Finding mean and median \n",
    "\n",
    "- Print the mean and median number of charges per `CASE_PARTICIPANT_ID`\n",
    "- Print the mean and median number of participants per `CASE_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here finding mean and median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07eb61b",
   "metadata": {},
   "source": [
    "### 2.3.4 Does the data enable us to follow the same defendant across different cases they're charged in? Write 1 sentence in support of your conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here checking for linkage of people across cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801605da",
   "metadata": {},
   "source": [
    "(your text response here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b0075",
   "metadata": {},
   "source": [
    "## 2.4 Which offense is final? (3 points)\n",
    "\n",
    "First, read the data documentation ([link here](https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf)) and summarize in your own words the differences between `OFFENSE_CATEGORY` and `UPDATED_OFFENSE_CATEGORY`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdbe2e0",
   "metadata": {},
   "source": [
    "(your text response here summarizing the differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19a9a8",
   "metadata": {},
   "source": [
    "Then construct an indicator `is_changed_offense` that's True for case-participant-charge observations (rows) where there's a difference between the `OFFENSE_CATEGORY` and the `UPDATED_OFFENSE_CATEGORY`. \n",
    "\n",
    "**Resources**: row subsetting, groupby/agg, and np.where covered in [lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/02_qss20_fa22_pandas.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ab5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here constructing indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914a53f",
   "metadata": {},
   "source": [
    "What are some of the more common changed offenses? Consider both:\n",
    "  - The raw number of changed offenses that come from each `OFFENSE_CATEGORY` (e.g., using `value_counts()`). This should answer the question: What offenses contribute the most to the pool of changed offenses?\n",
    "  - The proportion of each `OFFENSE_CATEGORY` that gets changed (can just compute mean and print result of `sort_values()`). This should answer the question: What offenses tend to get changed the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a87c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here inspecting most common changed offenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430a9b1",
   "metadata": {},
   "source": [
    "Print one example of a changed offense from one of these categories and comment on what the reason may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here printing example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7085baf",
   "metadata": {},
   "source": [
    "## 2.5 Simplifying the charges (5 points)\n",
    "\n",
    "Using the field (`UPDATED_OFFENSE_CATEGORY`), create a new field, `simplified_offense_derived`, that simplifies the many offense categories into broader buckets using the following process:\n",
    "\n",
    "First, create a new variable that strips \"Aggravated\" (capitalized) from the `UPDATED_OFFENSE_CATEGORY` (e.g., 'Aggravated Battery' just becomes 'Battery', 'Aggravated DUI' becomes 'DUI')\n",
    "\n",
    "**Resources**: slide 19 of [the lecture on data wrangling with pandas](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/02_qss20_fa22_pandas.pdf) has str.replace (example with stripping the name johnson from a last name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91456da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here stripping 'Aggravated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe13c8",
   "metadata": {},
   "source": [
    "Then:\n",
    "- Combine all offenses with 'Arson' in the string into a single `Arson` category\n",
    "- Combine all offenses with 'Homicide' in the string into a single `Homicide` category\n",
    "- Combine all offenses with 'Vehic' in the string into a single `Vehicle-related` category\n",
    "- Combine all offenses with 'Battery' in the string into a single `Battery` category\n",
    "- Use the simplified offense variable created above (the one without 'Aggravated') as the fallback/default value (instead of 'other')\n",
    "\n",
    "Do so efficiently, using `map()` with a dictionary or `np.select()` (or a similar procedure for systematic recoding) rather than separate line for each recoded offense.\n",
    "\n",
    "**Resources**:\n",
    "- [Activity code](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/00_pandas_datacleaning_solutions.ipynb) and [lecture on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/02_qss20_fa22_pandas.pdf) cover `np.select` and `map()` with a dictionary (can use one or the other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafcfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here combining offenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ed421",
   "metadata": {},
   "source": [
    "Print the difference between the # of unique offenses in the original `UPDATED_OFFENSE_CATEGORY` field and the # of unique offenses in your new `simplified_offense_derived` field. How many and which ones change?\n",
    "\n",
    "*Hint*: You can turn unique values from a column into a list using `df[col].unique().tolist()` and get the difference between two lists using a list comprehension: `[elem for elem in list1 if elem not in list2]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d746073",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here printing differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e097a7",
   "metadata": {},
   "source": [
    "## 2.6 Cleaning additional variables (10 points)\n",
    "\n",
    "When cleaning the following variables, make sure to retain the original variable in data. We tell you to use the derived suffix so it's easier to pull these cleaned out variables later.\n",
    "\n",
    "**Resources**: `np.where` in [lecture on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/02_qss20_fa22_pandas.pdf)\n",
    "\n",
    "### 2.6.1: Race\n",
    "Based on the `RACE` column, create True/false indicators for `is_black_derived` (Black only or `White/Black [Hispanic or Latino]`), `is_hisp_derived` (Non-Black Hispanic, so either hispanic alone or white hispanic), `is_white_derived` (White non-hispanic), or `is_other_derived` (none of the above). \n",
    "\n",
    "You can think of these indicators like this:\n",
    "\n",
    "`is_black_derived`: True if {Black only, White/Black [Hispanic or Latino]}, else False <br/>\n",
    "`is_hisp_derived`: True if {HISPANIC or White [Hispanic or Latino]}, else False <br/>\n",
    "`is_white_derived`: True if White, else False <br/>\n",
    "`is_other_derived`: True if is_black_derived == is_hisp_derived == is_white_derived == False, else False. In other words, this indicator should be True for all the races that were not included in any of the previous indicators; otherwise, it should be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here deriving race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7d519",
   "metadata": {},
   "source": [
    "### 2.6.2: Gender\n",
    "Based on the `GENDER` column, create a boolean true/false indicator for `is_male_derived` (false is female, unknown, or other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here deriving gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94592511",
   "metadata": {},
   "source": [
    "### 2.6.3: Age at incident\n",
    "Looking at the `AGE_AT_INCIDENT` column, you may notice outliers like 130-year olds. Recode the top 0.01% of values to be equal to the 99.99th percentile value (this is sometimes called `winsorizing` but don't worry about the terminology). Call this `age_derived`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e920bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here deriving age at incident"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eab212",
   "metadata": {},
   "source": [
    "### 2.6.4: Sentencing date\n",
    "Create `sentenceymd_derived` that's a version of `SENTENCING_DATE` converted to datetime format. Also create a rounded version, `sentenceym_derived`, that's rounded down to the first of the month and the year (e.g., 01-05-2016 and 01-27-2016 each become 01-01-2016). \n",
    "\n",
    "*Hints*: All timestamps are midnight so you can strip the timestamp. Before converting, you'll notice that some of the years have been mistranscribed (e.g., 291X or 221X instead of 201X). Programatically fix those (eg 2914 -> 2014). You can use this regex code to clean the dates or write your own pattern: ### first, use regex to clean up the date columns\n",
    "\n",
    "```python\n",
    "sentence['tmp_clnsdate'] = [re.sub(r'2[1-9]([0-9]+)', r\"20\\1\", str(date)) \n",
    "                            if bool(re.search('\\/2[1-9][0-9]+', str(date))) else \n",
    "                            str(date) \n",
    "                            for date in \n",
    "                            sentence.SENTENCE_DATE]\n",
    "```\n",
    "\n",
    "Even after cleaning, there will still be some that are after the year 2021 that we'll filter out later.\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- pd.to_datetime() used in [the data wrangling activity](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/00_pandas_datacleaning_solutions.ipynb)\n",
    "- extract the month and year from a datetime object using the dt accessor (similar syntax for year): https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here that creates datetime version of sentencing date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e0316",
   "metadata": {},
   "source": [
    "### 2.6.5: Sentencing judge\n",
    "\n",
    "Create an identifier (`judgeid_derived`) for each unique judge (`SENTENCE_JUDGE`) structured as judge_1, judge_2, etc. \n",
    "\n",
    "When finding unique judges, there are various duplicates we could weed out. For this exercise, address only these sources of duplication/redundancy:\n",
    "1. the different iterations of Doug/Douglas Simpson\n",
    "2. the different iterations of Shelley Sutker (who appears both with her maiden name and her hyphenated married name) \n",
    "\n",
    "Note that you can do this more manually by creating a list with the different name variations and receive full credit (i.e., no need to use regular expressions).\n",
    "\n",
    "*Hint 1*: due to mixed types, you may need to cast the `SENTENCE_JUDGE` var to a diff type in order to be able to sort.\n",
    "\n",
    "*Hint 2*: To assign identifiers to the judges, try grouping them with `ngroup()`. You can read about [the parameters in the documentation.](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.ngroup.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here that creates unique judge identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd6084",
   "metadata": {},
   "source": [
    "Then print a random sample of 10 rows with the original and cleaned columns for the relevant variables\n",
    "\n",
    "**Resources**: [sample command here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here that prints sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83ab10",
   "metadata": {},
   "source": [
    "## 2.7 Subsetting rows to analytic dataset (5 points)\n",
    "\n",
    "Let's narrow down the above sentencing dataset in a few ways. First, subset to cases where only one participant is charged, since cases with >1 participant might have complications like plea bargains/informing from other participants affecting the sentencing of the focal participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to limit to one participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10653c",
   "metadata": {},
   "source": [
    "Next, let's go from a participant-case level dataset, where each participant is repeated across charges tied to the case, to a participant-level dataset, where each participant has one charge. To do this, let's subset to a participant's primary charge and their current sentence (`PRIMARY_CHARGE_FLAG` is True and `CURRENT_SENTENCE_FLAG` is True). Double check that this worked by confirming there are no longer multiple charges for the same case-participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to subset to primary charge and current sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ab00d",
   "metadata": {},
   "source": [
    "Finally, apply these two additional filters: \n",
    "\n",
    "- filter out observations where judge is nan or nonsensical (indicated by `is.null` or equal to `FLOOD`)\n",
    "- subset to sentencing date between `01-01-2012` and `04-05-2021` (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca781e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to apply remaining filters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
